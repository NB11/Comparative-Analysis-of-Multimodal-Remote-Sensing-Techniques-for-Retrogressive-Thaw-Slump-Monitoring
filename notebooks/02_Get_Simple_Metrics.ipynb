{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code creates geojson files of the DEM and optical labels that are within the tiles\n",
    "\n",
    "# Further unionizes optical training and predictions labels so that there are no overlapping labels with the same year\n",
    "\n",
    "# It also calculates Area, Solidity, and Circularity of the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import rasterio as rio\n",
    "from shapely.geometry import Polygon\n",
    "from mpl_toolkits.basemap import Basemap  \n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.ops import unary_union\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import MultiPolygon\n",
    "import geopandas as gpd\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "# Unionize the touching geometries with same year to create single polygons \n",
    "def unionize_geometries_by_year(geo_df, year_column='year', geometry_column='geometry'):\n",
    "    union_results = []\n",
    "    years = geo_df[year_column].unique()\n",
    "\n",
    "    for year in years:\n",
    "        subset = geo_df[geo_df[year_column] == year]\n",
    "        \n",
    "        # Find touching groups\n",
    "        touching_groups = [list(group[geometry_column]) for _, group in subset.groupby(subset.touches(subset))]\n",
    "        \n",
    "        # Unionize touching groups\n",
    "        unionized_touching_group = unary_union(touching_groups)\n",
    "        \n",
    "        # Find polygons that don't touch any other polygon within the same year\n",
    "        non_touching_polygons = subset[~subset.index.isin(subset.touches(subset).index)]\n",
    "        \n",
    "        # Add non-touching polygons to the union results only if they exist\n",
    "        if not non_touching_polygons.empty:\n",
    "            non_touching_geometries = list(non_touching_polygons[geometry_column])\n",
    "            for geometry in non_touching_geometries:\n",
    "                union_results.append({year_column: year, geometry_column: geometry})\n",
    "        \n",
    "        # Add unionized touching group to the union results\n",
    "        if unionized_touching_group.is_empty == False:\n",
    "            union_results.append({year_column: year, geometry_column: unionized_touching_group})\n",
    "\n",
    "    # Create a GeoDataFrame from the results list\n",
    "    union_df = gpd.GeoDataFrame(union_results, crs=geo_df.crs)\n",
    "    union_df = union_df.explode()\n",
    "    \n",
    "    return union_df\n",
    "\n",
    "# Area\n",
    "def get_area(labels):\n",
    "    labels['area'] = labels['geometry'].area\n",
    "    return labels\n",
    "\n",
    "# Circularity\n",
    "def get_circularity(geometry):\n",
    "    perimeter = geometry.length\n",
    "    area = geometry.area\n",
    "    circularity = (4 * math.pi * area) / (perimeter ** 2)\n",
    "    return circularity\n",
    "\n",
    "#Solidity\n",
    "def get_solidity(geometry):\n",
    "    convexhull = geometry.convex_hull\n",
    "    convexhull = convexhull.area\n",
    "    area = geometry.area\n",
    "    solidity = area / convexhull\n",
    "    return solidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_region(region_name, footprint_file):\n",
    "    # Optical Label Files\n",
    "    optical_training_labels = gpd.read_file('labels\\\\optical_labels\\\\optical_training_labels.geojson')\n",
    "    optical_prediction_labels = gpd.read_file('labels\\\\optical_labels\\\\optical_predictions.gpkg')\n",
    "\n",
    "    # Read DEM label files\n",
    "    DEM_labels = gpd.read_file(f'labels\\\\DEM_labels\\\\{region_name}_DEM_labels_rasterized.geojson')\n",
    "\n",
    "    # Read Tiles and Footprints\n",
    "    tiles = gpd.read_file(f'Results\\\\{region_name}\\\\Footprints\\\\{region_name}_area.geojson')\n",
    "    footprint = gpd.read_file(f'boundries\\\\footprints\\\\CRS_adjusted\\\\{footprint_file}')\n",
    "\n",
    "    # Spatial join Footprint with Tiles\n",
    "    fp = gpd.sjoin(footprint, tiles, predicate='overlaps', how='inner')\n",
    "    fp = fp.drop_duplicates(subset='image_id')\n",
    "    fp = fp.drop(columns=['index_right', 'datasource', 'subset', 'fid', 'tile_name'])\n",
    "    fp['region'] = region_name\n",
    "\n",
    "    # Footprint year\n",
    "    fp['image_year'] = pd.to_datetime(fp['image_date']).dt.year\n",
    "\n",
    "    years = fp['image_year'].unique()\n",
    "\n",
    "    for year in years:\n",
    "        fp_year = fp[fp['image_year'] == year]\n",
    "        fp_year_union = unary_union(fp_year['geometry'])\n",
    "        fp_year = gpd.GeoDataFrame(geometry=[fp_year_union], crs=fp.crs)\n",
    "        fp_year.to_file(f'Results\\\\{region_name}\\\\Footprints\\\\footprint_{region_name}_' + str(year) + '.geojson')\n",
    "\n",
    "    # Spatial join for Optical and DEM labels\n",
    "    OP_lab = gpd.sjoin(optical_prediction_labels, tiles, predicate='within',how='inner')\n",
    "    OT_lab = gpd.sjoin(optical_training_labels, tiles, predicate='within', how='inner')\n",
    "    DEM_labels = gpd.sjoin(DEM_labels, tiles, predicate='within', how='inner')\n",
    "\n",
    "    # Get Rid of Unnecessary Columns\n",
    "    DEM_labels = DEM_labels.drop(columns=['index_right', 'tile_name'])\n",
    "    OT_lab = OT_lab.drop(columns=['index_right', 'site', 'id_ds', 'label', 'datasource', 'fid', 'subset', 'target', 'author', 'id', 'image_id', 'layer','tile_name'])    \n",
    "    OP_lab = OP_lab.drop(columns=['index_right', 'satellite', 'image_id', 'DN', 'tile_id', 'take_id', 'tile_name'])\n",
    "\n",
    "    # Processing and saving labels with metrics\n",
    "    OT_lab['year'] = pd.to_datetime(OT_lab['image_date']).dt.year\n",
    "    OT_lab.geometry = OT_lab.geometry.buffer(0)\n",
    "    OT_lab = unionize_geometries_by_year(OT_lab)\n",
    "    OP_lab = unionize_geometries_by_year(OP_lab)\n",
    "    OP_lab['region'] = region_name\n",
    "    OT_lab['region'] = region_name\n",
    "    DEM_labels['region'] = region_name\n",
    "\n",
    "    Labels = [DEM_labels, OT_lab, OP_lab]\n",
    "\n",
    "    for label in Labels:\n",
    "        label = get_area(label)\n",
    "        label['circularity'] = label['geometry'].apply(get_circularity)\n",
    "        label['solidity'] = label['geometry'].apply(get_solidity)\n",
    "\n",
    "    # Save files with metrics\n",
    "    OT_lab.to_file(f'labels\\\\labels_w_metrics\\\\{region_name}_OT_labels_unionized_SimpleMetrics.geojson', driver='GeoJSON')\n",
    "    OP_lab.to_file(f'labels\\\\labels_w_metrics\\\\{region_name}_OP_labels_unionized_SimpleMetrics.geojson', driver='GeoJSON')\n",
    "    DEM_labels.to_file(f'labels\\\\labels_w_metrics\\\\{region_name}_DEM_labels_rasterized_SimpleMetrics.geojson', driver='GeoJSON')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noe\\AppData\\Local\\Temp\\ipykernel_28584\\1084091739.py:34: FutureWarning: Currently, index_parts defaults to True, but in the future, it will default to False to be consistent with Pandas. Use `index_parts=True` to keep the current behavior and True/False to silence the warning.\n",
      "  union_df = union_df.explode()\n",
      "C:\\Users\\Noe\\AppData\\Local\\Temp\\ipykernel_28584\\1084091739.py:34: FutureWarning: Currently, index_parts defaults to True, but in the future, it will default to False to be consistent with Pandas. Use `index_parts=True` to keep the current behavior and True/False to silence the warning.\n",
      "  union_df = union_df.explode()\n",
      "C:\\Users\\Noe\\AppData\\Local\\Temp\\ipykernel_28584\\1084091739.py:34: FutureWarning: Currently, index_parts defaults to True, but in the future, it will default to False to be consistent with Pandas. Use `index_parts=True` to keep the current behavior and True/False to silence the warning.\n",
      "  union_df = union_df.explode()\n",
      "C:\\Users\\Noe\\AppData\\Local\\Temp\\ipykernel_28584\\1084091739.py:34: FutureWarning: Currently, index_parts defaults to True, but in the future, it will default to False to be consistent with Pandas. Use `index_parts=True` to keep the current behavior and True/False to silence the warning.\n",
      "  union_df = union_df.explode()\n",
      "C:\\Users\\Noe\\AppData\\Local\\Temp\\ipykernel_28584\\1084091739.py:34: FutureWarning: Currently, index_parts defaults to True, but in the future, it will default to False to be consistent with Pandas. Use `index_parts=True` to keep the current behavior and True/False to silence the warning.\n",
      "  union_df = union_df.explode()\n",
      "C:\\Users\\Noe\\AppData\\Local\\Temp\\ipykernel_28584\\1084091739.py:34: FutureWarning: Currently, index_parts defaults to True, but in the future, it will default to False to be consistent with Pandas. Use `index_parts=True` to keep the current behavior and True/False to silence the warning.\n",
      "  union_df = union_df.explode()\n",
      "C:\\Users\\Noe\\AppData\\Local\\Temp\\ipykernel_28584\\1084091739.py:34: FutureWarning: Currently, index_parts defaults to True, but in the future, it will default to False to be consistent with Pandas. Use `index_parts=True` to keep the current behavior and True/False to silence the warning.\n",
      "  union_df = union_df.explode()\n",
      "C:\\Users\\Noe\\AppData\\Local\\Temp\\ipykernel_28584\\1084091739.py:34: FutureWarning: Currently, index_parts defaults to True, but in the future, it will default to False to be consistent with Pandas. Use `index_parts=True` to keep the current behavior and True/False to silence the warning.\n",
      "  union_df = union_df.explode()\n"
     ]
    }
   ],
   "source": [
    "# Define regions and corresponding footprints\n",
    "regions_footprints = {\n",
    "    'herschel': 'footprint001.geojson',\n",
    "    'kolguev': 'footprint001.geojson',\n",
    "    'peel': 'footprint002.geojson',\n",
    "    'gydan': 'footprint003.geojson'\n",
    "}\n",
    "\n",
    "# Process each region\n",
    "for region, footprint_file in regions_footprints.items():\n",
    "    process_region(region, footprint_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
